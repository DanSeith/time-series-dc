{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Figure2plots' from 'C:\\\\Users\\\\codyt\\\\Documents\\\\repos\\\\time-series-dc\\\\Figure2plots.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "from skimage.measure import regionprops\n",
    "import cv2 as cv\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import string\n",
    "from PIL import Image\n",
    "from scipy import signal\n",
    "from scipy.interpolate import interp1d\n",
    "from skimage import measure\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from skimage.draw import rectangle\n",
    "import importlib\n",
    "import splitfolders\n",
    "from scipy.stats import gaussian_kde\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import itertools\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "import plots\n",
    "import df_utils\n",
    "importlib.reload(df_utils)\n",
    "import features\n",
    "import Figure2plots\n",
    "importlib.reload(Figure2plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length prefilter: 2337\n",
      "Length postfilter: 1992\n",
      "1564\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle('D://Datasets//full_data101x56_2_xc_fixed_calcs')\n",
    "df = df_utils.filter_df(df,ymax=5,max_ar=1.1,radius_std=5)\n",
    "df = df[(df.cell=='hl60')|(df.cell=='hl60d')]\n",
    "df = df[np.logical_not((df.cell=='hl60')&(df.date=='11-3-20')&(df.run=='0'))]\n",
    "df = df[np.logical_not((df.cell=='hl60')&(df.date=='11-5-20')&(df.run=='3'))]\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['event', 'tf', 'mask', 'perimeter', 'area', 'circ', 'deform', 'r_um',\n",
       "       'xcm_um', 'yc_um', 'perimeter_cx', 'area_cx', 'circ_cx', 'deform_cx',\n",
       "       'r_um_cx', 'xc_um_el', 'yc_um_el', 'a', 'b', 'aspect', 'r_um_el',\n",
       "       'cell', 'date', 'run', 'r_idx', 'nar1_idx', 'nar2_idx', 'cav_idx',\n",
       "       'out1_idx', 'out2_idx', 'rad', 'nar1_def', 'nar2_def', 'cav1_def',\n",
       "       'r_el', 'nar1_asp', 'nar2_asp', 'cav1_asp', 'nar1_max_arg',\n",
       "       'nar2_max_arg', 'cav1_min_arg', 'x_poly1', 'x_poly2', 'region1_dx',\n",
       "       'region1_dt', 'region1_dasp', 'delta_asp', 'v_avg', 'mean_area',\n",
       "       'mean_perimeter', 'mean_aspect'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['r1_slope']=df.apply(lambda a: a.x_poly1[0],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1], dtype=int8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cell.astype('category').cat.codes.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = ['nar1_asp', 'nar2_asp', 'rad']\n",
    "\n",
    "# Extract features\n",
    "x = df[feature_list].to_numpy()\n",
    "y = df.cell.astype('category').cat.codes.to_numpy()\n",
    "\n",
    "# Normalize and standardize first\n",
    "scalar = sklearn.preprocessing.StandardScaler()\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.3, random_state=123)\n",
    "\n",
    "# Fit scalar on training, apply transformation to val/test\n",
    "scalar.fit(x_train)\n",
    "x_train = scalar.transform(x_train)\n",
    "x_val = scalar.transform(x_val)\n",
    "\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_val, y_val, test_size=0.5, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = KNeighborsClassifier()\n",
    "clf.fit(x_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6297872340425532"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nar1_asp',), ('nar2_asp',), ('rad',)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(itertools.combinations(feature_list, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.744272872263303\n",
      "['nar2_asp', 'rad', 'r1_slope', 'delta_asp']\n",
      "0.676595744680851\n"
     ]
    }
   ],
   "source": [
    "feature_list = ['nar1_asp', 'nar2_asp', 'rad','r1_slope','delta_asp']\n",
    "label = []\n",
    "score = []\n",
    "auc = []\n",
    "aic = []\n",
    "\n",
    "for i in range(len(feature_list)):\n",
    "    \n",
    "    sub_feats = list(itertools.combinations(feature_list, i+1))\n",
    "    \n",
    "    for j,feats in enumerate(sub_feats):\n",
    "        x = df[list(feats)].to_numpy()\n",
    "        y = df.cell.astype('category').cat.codes.to_numpy()\n",
    "        \n",
    "        # Normalize and standardize first\n",
    "        scalar = sklearn.preprocessing.StandardScaler()\n",
    "        x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.3, random_state=123)\n",
    "\n",
    "        # Fit scalar on training, apply transformation to val/test\n",
    "        scalar.fit(x_train)\n",
    "        x_train = scalar.transform(x_train)\n",
    "        x_val = scalar.transform(x_val)\n",
    "        \n",
    "        clf = KNeighborsClassifier(n_neighbors=10)\n",
    "        clf.fit(x_train, y_train.ravel())\n",
    "        \n",
    "        score.append(clf.score(x_val, y_val))\n",
    "        label.append(list(feats))\n",
    "        \n",
    "        auc.append(roc_auc_score(y_val, clf.predict_proba(x_val)[:,1]))\n",
    "        \n",
    "        #y_hat = logreg.predict(x_val)\n",
    "        #resid = y_val - y_hat\n",
    "        #sse = sum(resid**2)\n",
    "        #k= 2\n",
    "        #AIC= 2*k - 2*np.log(sse)\n",
    "        #aic.append(AIC)\n",
    "        \n",
    "print(np.max(auc))\n",
    "print(label[np.argmax(auc)])\n",
    "print(score[np.argmax(auc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7258046976946498\n",
      "['nar1_asp', 'rad', 'r1_slope']\n",
      "0.6723404255319149\n"
     ]
    }
   ],
   "source": [
    "feature_list = ['nar1_asp', 'nar2_asp', 'rad','r1_slope','delta_asp']\n",
    "label = []\n",
    "score = []\n",
    "auc = []\n",
    "aic = []\n",
    "\n",
    "for i in range(len(feature_list)):\n",
    "    \n",
    "    sub_feats = list(itertools.combinations(feature_list, i+1))\n",
    "    \n",
    "    for j,feats in enumerate(sub_feats):\n",
    "        x = df[list(feats)].to_numpy()\n",
    "        y = df.cell.astype('category').cat.codes.to_numpy()\n",
    "        \n",
    "        # Normalize and standardize first\n",
    "        scalar = sklearn.preprocessing.StandardScaler()\n",
    "        x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.3, random_state=123)\n",
    "\n",
    "        # Fit scalar on training, apply transformation to val/test\n",
    "        scalar.fit(x_train)\n",
    "        x_train = scalar.transform(x_train)\n",
    "        x_val = scalar.transform(x_val)\n",
    "        \n",
    "        logreg = LogisticRegression()\n",
    "        logreg.fit(x_train,y_train)\n",
    "        \n",
    "        score.append(logreg.score(x_val, y_val))\n",
    "        label.append(list(feats))\n",
    "        \n",
    "        auc.append(roc_auc_score(y_val, logreg.predict_proba(x_val)[:,1]))\n",
    "        \n",
    "        #y_hat = logreg.predict(x_val)\n",
    "        #resid = y_val - y_hat\n",
    "        #sse = sum(resid**2)\n",
    "        #k= 2\n",
    "        #AIC= 2*k - 2*np.log(sse)\n",
    "        #aic.append(AIC)\n",
    "\n",
    "print(np.max(auc))\n",
    "print(label[np.argmax(auc)])\n",
    "print(score[np.argmax(auc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nar1_asp', 'rad', 'r1_slope']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label[np.argmax(auc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6723404255319149"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score[np.argmax(auc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_search(feats)\n",
    "\n",
    "    # Extract features\n",
    "    x = df[feature_list].to_numpy()\n",
    "    y = df[['y']].to_numpy()\n",
    "\n",
    "    # Normalize and standardize first\n",
    "    scalar = sklearn.preprocessing.StandardScaler()\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.3, random_state=123)\n",
    "\n",
    "    # Fit scalar on training, apply transformation to val/test\n",
    "    scalar.fit(x_train)\n",
    "    x_train = scalar.transform(x_train)\n",
    "    x_val = scalar.transform(x_val)\n",
    "\n",
    "    x_val, x_test, y_val, y_test = train_test_split(x_val, y_val, test_size=0.5, random_state=123)\n",
    "\n",
    "    # Grid search all hyperparameters\n",
    "    leaf_size = list(range(1, 200, 5))\n",
    "    neighbors = np.arange(1, 25)\n",
    "    score = {}\n",
    "    for leaf in leaf_size:\n",
    "        for n in neighbors:\n",
    "            clf = KNeighborsClassifier(n_neighbors=n, leaf_size=leaf)\n",
    "            clf.fit(x_train, y_train.ravel())\n",
    "            score[(str(n), str(leaf))] = clf.score(x_val, y_val)\n",
    "\n",
    "    # Select best weights\n",
    "    n, leaf = max(score, key=lambda key: score[key])\n",
    "\n",
    "    print('Optimized hyper params:')\n",
    "    print('N: ', n, '\\n', 'Leaf size: ', leaf)\n",
    "    clf = KNeighborsClassifier(n_neighbors=int(n), leaf_size=int(leaf))\n",
    "    clf.fit(x_train, y_train.ravel())\n",
    "    print(clf.score(x_test, y_test))\n",
    "\n",
    "    sklearn.metrics.plot_roc_curve(clf, x_test, y_test)\n",
    "    plt.title('k Nearest Neighbors' + ' K: ' + str(n) + ' Leaf Size: ' + str(leaf))\n",
    "    plt.savefig('knn_roc.png', dpi=300)\n",
    "\n",
    "    pickle.dump(clf, open('knn.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aktwelve]",
   "language": "python",
   "name": "conda-env-aktwelve-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
